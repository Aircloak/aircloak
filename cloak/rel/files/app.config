[
  {kernel, [
    %% The portnumber the cloak erlang vm listens
    %% to for communication from other nodes.
    {inet_dist_listen_min, 34423},
    {inet_dist_listen_max, 34423}
  ]},

  %% Parameters for reporting high memory/disk usage. See os_mon docs for more details.
  {os_mon, [
    %% Check RAM usage every minute, set alarm if more than 70% used.
    {memory_check_interval, 1},
    {system_memory_high_watermark, 0.7},
    %% Check disk usage every minute, set alarm if more than 80% used.
    {disk_space_check_interval, 1},
    {disk_almost_full_threshold, 0.8}
  ]},

  %% Lager Config
  {lager, [
    %% What handlers to install with what arguments
    %% The defaults for the logfiles are to rotate the files when
    %% they reach 10Mb or at midnight, whichever comes first, and keep
    %% the last 5 rotations. See the lager README for a description of
    %% the time rotation format:
    %% https://github.com/basho/lager/blob/master/README.org
    %%
    %% If you wish to disable rotation, you can either set the size to 0
    %% and the rotation time to "", or instead specify a 2-tuple that only
    %% consists of {Logfile, Level}.
    %%
    %% If you wish to have riak log messages to syslog, you can use a handler
    %% like this:
    %%   {lager_syslog_backend, ["riak", daemon, info]},
    %%
    {handlers, [
      {lager_syslog_backend, ["cloak-core", daemon, info]},
      {lager_console_backend, info}
    ]},

    %% disable lager crash log
    {crash_log, undefined},

    %% Get coloured output with Erlang R16B and newer (if lager >= 2)
    {colored, true},

    %% disable lager error_logger connector
    {error_logger_redirect, false}
  ]},

  %% SASL config
  {sasl, [
    {sasl_error_logger, false}
  ]},

  %% webmachine config
  {webmachine, [
    {error_handler, cloak_webmachine_error_handler},
    {server_name, "Cloak API"}
  ]},

  {cloak, [
    {ring, [
      %% Where the ring state is stored.
      %% Persisting the ring between executions,
      %% allows a cloak cluster to continue
      %% operation after a machine restart.
      {dir, "/mnt/crypt/cloak_data"},

      %% The number of partitions used in the Aircloak storage
      %% ring affects performance in many ways. The number of
      %% partitions should therefore be chosen carefully.
      %% Things to consider:
      %% - the higher the number of partitions:
      %%   - the easier it is to spread the data evenly across
      %%     multiple cloaks
      %%   - the more distinct database tables are created
      %%     per postgres instance, as we create one table
      %%     per partition and user table
      %%   - the more fragmented queries are executed, as they
      %%     are executed once per partition a node is responsible for
      %% - You are a computer scientist, so you should probably choose
      %%   a ring-size that is a power of two. It doesn't have any
      %%   real implication on the usage of the system, but it is
      %%   significantly cooler, and makes us all feel better about it.
      {size, 105},

      %% The number of replicas we store of any piece of information.
      %% This allows at most the loss of N-1 machines without loosing the
      %% ability to read and write data.
      {replicas, 3},

      %% This is the amount of time in milliseconds to wait before a
      %% migration is triggered when something about the ring has to
      %% change (like after generating a ring join).  Default value
      %% is 5 minutes.
      {wait_before_migration, 300000},

      %% This is the amount of time to wait between two checks if we should
      %% do a migration in the migration_daemon.  Default value is 15 minutes.
      {wait_between_migration_checks, 900000},

      %% How many concurrent partition migrations we allow affect the overall
      %% state of the cluster. The higher the number, the more bandwidth and
      %% resources will be consumed during the migration. At the extreme the
      %% network could be completely saturated by moving the data around.
      %% Setting the value too low will result in migrations taking prohibitively
      %% long.
      {allowed_concurrent_partition_migrations, 4},

      %% How long the migration of a single partition table is allowed to take,
      %% before the cloak times out. The value should either be numeric and in ms,
      %% or `infinity`, although the latter is strongly discouraged as we want to
      %% know when things go wrong.
      {per_partition_migration_timeout, 3600000} % 1 hour
    ]},

    {api, [
      %% The HTTP API provided by cloak-core
      %% should bind to
      {address, "127.0.0.1"},
      %% on port
      {port, 8098}
    ]},

    {air, [
      %% The URL that results from asynchronous queries are sent to
      {return_url, "https://infrastructure-api.aircloak.com/results"}
    ]},

    {queries, [
      %% The time to wait for the task coordinator to finish
      %% the query. If it hasn't responded in that time, the
      %% query times out completely, without any answers.
      {query_timeout, 3600000}, % 1 hour

      %% The time we wait in synchronous queries for the task
      %% to finish.  The timeout is set relatively high to allow
      %% more complex tasks to be run synchronously without
      %% having to pass through the web.
      %% Once we have AirPub in place as a central dispatch
      %% point for query results, we should reduce the
      %% synchronous query timeout to reduce the number of
      %% file descriptions potentially help open concurrently.
      {sync_query_timeout, 3600000},

      %% This is the number of concurrent task_coordinators that
      %% are spawned per node.  If we run out of task_coordinators
      %% the queued_worker mechanism queues tasks and runs them as
      %% soon as a task_coordinator finished processing a task.
      {concurrent_executions, 3}
    ]},

    {durability, [
      %% How many nodes we store data about users on.
      %% This affects how many nodes we can allow to fail
      %% before we loose access to data.
      {users_num_storage_nodes, 3}
    ]},

    {noise, [
      %% The minimum number of users that must be in a bucket to get reported.
      {absolute_lower_bound, 2},

      %% After adding noise with standard deviation sigma_soft_lower_bound to the number of users in a bucket
      %% this noisy count has to be greater than soft_lower_bound to get reported.
      {sigma_soft_lower_bound, 1},
      {soft_lower_bound, 5},

      %% target_error: The target error for which the anonymization engine will add noise to the results.
      {target_error, 0.01},

      %% min_sigma: The minimum standard deviation allowed for noise.
      %% max_sigma: The maximum total standard deviation to be used. This can be exceeded without
      %% causing privacy issues, but is honoured to improve the usability of the system.
      {min_sigma, 2},
      {max_sigma, 20},

      % Percentile of users that will be discarded due to high-touch suppression. Percentile is taken
      % over the report ratio of each user, where a user's report ratio is reported_count/queried_count.
      {high_touch_suppression_percentile, 0.00001},

      % Recalculation intervals for report ratio calculation. A recalculation interval is number
      % of times a user is queried, after which his report ratio is recalculated.
      {high_touch_suppression_recalc_intervals, [100, 1000, 10000, 100000]},

      %% The anonymized results contain a layer of noise that is constant and unique to
      %% the bucket. The noise is normal with a certain standard deviation.
      {constant_noise_sd, 1.5}
    ]},

    {metrics, [
      %% Graphite server and pickle port
      {graphite_server, "cloakmetrics.mpi-sws.org"},
      {graphite_port, 2004}
    ]},

    {cloak_db, [
      % Default cloak database parameters (server is excluded)
      {connection, [
        {user, "cloak"},
        {database, "cloak"},
        {port, 5432}
      ]},
      % Default server-side timeout. The client-side timeout is 5 seconds longer.
      {default_query_timeout, 20000},
      % Per-server connection pool sizes. Each tuple defines number of static (started immediately and
      % persisted) workers in the pool
      % The static count can also be set relative to the CPU count by specifying
      % a floating-point multiplier before the fixed amount of workers.
      {pool_size, {1.5, 3}}, % num_cpus * 1.5 + 3
      % The default timeout for migrations.
      {default_migration_timeout, 3600000}, % 1 hour
      {idle_timeout, 60000} % 1 minute
    ]},

    {sandbox, [
      %% The sandbox executable executing tasks in the lua
      {binary, "priv/sandbox"},

      %% Number of ms a job is allowed to execute in the sandbox before being terminated
      {max_time, 120000} % 2 minutes
    ]},

    {bucket_cache, [
      %% Expiry time in milliseconds. After this time, the cache process is terminated.
      {expiry, 3600000} % 1 hour
    ]},

    {user_tables, [
      %% erlcron spec for running table cleanup job
      {cleanup_job_cron_spec, {daily, {0, 0, 0}}}
    ]},

    {global_service, [
      %% M:F for providing list of default nodes for global service
      {default_nodes, {ring_state, available_nodes_of_active_ring}}
    ]}
  ]},

  {pidder, [
    %% Name of your application.
    %% Affects the location at which the pid is stored.
    {name, cloak_core},

    %% Path to the directory on disk where your pid is
    %% stored.
    {dir, "/var/run"}
  ]}
].
