title: An introduction to uploading data
order: 1
content: |

  # Getting data into the system

  Before any analysis can take place, you need to import some data into your cloak cluster.

  Depending on your particular case, you might want to upload data all at once, or continuously as it becomes available to you.
  Either way, the data should describe discrete logical entities. An entity can be a human user, a car,
  or any other object that can be uniquely identified.
  For the remainder of this guide we are assuming the entity is a human user.

  The cloak does not impose any restrictions on how you name your users, but if you want to upload more data for a
  user who already has data in a cloak, the identifying name used, has to be the same as the one previously used.

  Before being able to upload data to a cluster, you need to prepare tables into which the data will be stored<%
    if has_user_tables? -%>
  , but that you already have done.
  <% else -%>
  .
  <% end -%>
  These tables dictate the format the cluster expects the data you upload to be in.


  ## Creating database tables

  Before uploading data to a cluster, you need to create the database tables that will hold the data in the cluster.
  It is good practise to name the table after what it stores. If you track user _location_ datapoints, you would for example
  create a table called __locations__.

  When defining a table you specify what columns the table contains. If you track entities in a cartesian coordinate space,
  you might have columns named __x__ and __y__ as well as __x_error__ and __y_error__, or if you use longitudes and
  latitudes, you could call your columns __lat__ and __lng__.

  A table can evolve over time. New columns can be added, and old ones removed. Getting the table design completely
  right from the outset is therefore not critical.

  For more information on creating tables, check out <%= help_link "managing-data" %>.


  ## Uploading data

  Once you have created database tables to hold your data, you can start uploading data into your cluster.

  The data is uploaded through an HTTP API that accepts data encoded as JSON.
  There are two end-points available. One accepts data for
  <%= site_link "/apidocs/index.html#single-user-data-insert", "individual users" %>,
  whereas the other allows for <%= site_link "/apidocs/index.html#bulk-insert", "bulk upload" %> of data
  for multiple users.

  Please consult the <%= site_link "/apidocs/index.html#cloak-apis", "API Docs" %> for the
  specifics.
